# USearch å¸¸è§é—®é¢˜è§£ç­” (FAQ)
## Frequently Asked Questions

---

## ğŸ“š ç›®å½•

1. [åŸºç¡€é—®é¢˜](#åŸºç¡€é—®é¢˜)
2. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
3. [åˆ†å¸ƒå¼éƒ¨ç½²](#åˆ†å¸ƒå¼éƒ¨ç½²)
4. [é”™è¯¯æ’æŸ¥](#é”™è¯¯æ’æŸ¥)
5. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
6. [é›†æˆé—®é¢˜](#é›†æˆé—®é¢˜)

---

## åŸºç¡€é—®é¢˜

### Q1: USearch å’Œå…¶ä»–å‘é‡æ•°æ®åº“ï¼ˆå¦‚ Faissã€Milvusï¼‰æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**A:**
| ç‰¹æ€§ | USearch | Faiss | Milvus |
|------|---------|-------|--------|
| éƒ¨ç½²æ–¹å¼ | åµŒå…¥å¼åº“ | åµŒå…¥å¼åº“ | ç‹¬ç«‹æœåŠ¡ |
| è¯­è¨€æ”¯æŒ | 10+ | C++/Python | Go/Python |
| ä¾èµ– | é›¶ä¾èµ– | ä¾èµ– NumPy | ä¾èµ–å¤š |
| åŠ¨æ€æ›´æ–° | âœ… åŸç”Ÿæ”¯æŒ | âš ï¸ æœ‰é™ | âœ… æ”¯æŒ |
| è·¨å¹³å° | âœ… å®Œå…¨è·¨å¹³å° | âš ï¸ éƒ¨åˆ†é™åˆ¶ | âš ï¸ ä¸»è¦ Linux |
| å­¦ä¹ æ›²çº¿ | ä½ | ä¸­ | é«˜ |
| é€‚ç”¨åœºæ™¯ | åµŒå…¥å¼åº”ç”¨ | ç¦»çº¿æœç´¢ | å¤§è§„æ¨¡æœåŠ¡ |

**é€‰æ‹©å»ºè®®**ï¼š
- åµŒå…¥å¼åº”ç”¨ â†’ USearch
- ç¦»çº¿æ‰¹å¤„ç† â†’ Faiss
- å¤§è§„æ¨¡åœ¨çº¿æœåŠ¡ â†’ Milvus

---

### Q2: å¦‚ä½•é€‰æ‹©åˆé€‚çš„è·ç¦»åº¦é‡ï¼Ÿ

**A:**

```cpp
// ä½™å¼¦è·ç¦»ï¼ˆæœ€å¸¸ç”¨ï¼‰
// é€‚ç”¨ï¼šæ–‡æœ¬ã€å›¾åƒåµŒå…¥ï¼ˆå·²å½’ä¸€åŒ–ï¼‰
index.init(128, metric_kind_t::cos_k);

// å†…ç§¯ï¼ˆç‚¹ç§¯ï¼‰
// é€‚ç”¨ï¼šæ¨èç³»ç»Ÿã€ä¸éœ€è¦å½’ä¸€åŒ–çš„å‘é‡
index.init(128, metric_kind_t::ip_k);

// æ¬§æ°è·ç¦»ï¼ˆL2ï¼‰
// é€‚ç”¨ï¼šè®¡ç®—æœºè§†è§‰ã€åæ ‡æ•°æ®
index.init(128, metric_kind_t::l2sq_k);
```

**å¿«é€Ÿé€‰æ‹©æŒ‡å—**ï¼š
| å‘é‡ç±»å‹ | æ¨èåº¦é‡ | åŸå›  |
|---------|---------|------|
| æ–‡æœ¬åµŒå…¥ï¼ˆBERTã€Sentence-Transformersï¼‰ | cos | å·²å½’ä¸€åŒ– |
| å›¾åƒç‰¹å¾ï¼ˆResNetã€CLIPï¼‰ | cos | å½’ä¸€åŒ–åç¨³å®š |
| æ¨èç³»ç»ŸåµŒå…¥ | ip | ç›´æ¥åæ˜ åå¥½ |
| åæ ‡ã€ä½ç½®æ•°æ® | l2sq | ç‰©ç†è·ç¦» |

---

### Q3: å‘é‡ç»´åº¦å¯¹æ€§èƒ½æœ‰å¤šå¤§å½±å“ï¼Ÿ

**A:**

```
æœç´¢æ—¶é—´å¤æ‚åº¦ï¼šO(d Ã— log(N) Ã— ef)
- d: å‘é‡ç»´åº¦
- N: å‘é‡æ•°é‡
- ef: æœç´¢èŒƒå›´

ç»´åº¦ç¿»å€ â†’ è·ç¦»è®¡ç®—æ—¶é—´ç¿»å€
```

**å®æµ‹æ•°æ®**ï¼ˆ1000ä¸‡å‘é‡ï¼‰ï¼š
| ç»´åº¦ | æ„å»ºæ—¶é—´ | æœç´¢å»¶è¿Ÿ | å†…å­˜ |
|------|---------|---------|------|
| 128 | 200s | 1.0ms | 1x |
| 256 | 350s | 1.8ms | 2x |
| 512 | 600s | 3.2ms | 4x |
| 768 | 900s | 4.5ms | 6x |
| 1024 | 1200s | 6.0ms | 8x |

**ä¼˜åŒ–å»ºè®®**ï¼š
- ä½¿ç”¨é™ç»´ï¼ˆPCAã€AutoEncoderï¼‰
- é‡åŒ–ï¼ˆf16ã€i8ï¼‰
- æ‰¹é‡æœç´¢

---

### Q4: å¦‚ä½•ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼Ÿ

**A:**

```
å†…å­˜ = å‘é‡æ•°æ® + ç´¢å¼•ç»“æ„ + å¼€é”€

å‘é‡æ•°æ® = N Ã— d Ã— bytes_per_scalar
ç´¢å¼•ç»“æ„ â‰ˆ N Ã— d Ã— bytes_per_scalar Ã— 0.3  (30%å¼€é”€)
```

**è®¡ç®—ç¤ºä¾‹**ï¼ˆ1000ä¸‡å‘é‡ï¼Œ768ç»´ï¼‰ï¼š
```
f32: 10M Ã— 768 Ã— 4 Ã— 1.3 = ~40 GB
f16: 10M Ã— 768 Ã— 2 Ã— 1.3 = ~20 GB
i8:  10M Ã— 768 Ã— 1 Ã— 1.3 = ~10 GB
```

**å¿«é€Ÿä¼°ç®—å·¥å…·**ï¼š
```python
def estimate_memory(n_vectors, dimensions, dtype='f32'):
    bytes_per_scalar = {'f32': 4, 'f16': 2, 'i8': 1}[dtype]
    base = n_vectors * dimensions * bytes_per_scalar
    overhead = base * 0.3
    return (base + overhead) / (1024**3)  # GB

# ç¤ºä¾‹
print(estimate_memory(10_000_000, 768, 'f16'))  # ~20 GB
```

---

## æ€§èƒ½ä¼˜åŒ–

### Q5: ä¸ºä»€ä¹ˆæˆ‘çš„æœç´¢å¾ˆæ…¢ï¼Ÿ

**A:** å¸¸è§åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š

**1. é…ç½®ä¸å½“**
```cpp
// âŒ å¤ªå°çš„ expansion
config.expansion = 16;

// âœ… åˆé€‚çš„å€¼
config.expansion = 64;  // å¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦
```

**2. æœªä½¿ç”¨æ‰¹é‡æ“ä½œ**
```cpp
// âŒ æ…¢ï¼šé€ä¸ªæ·»åŠ 
for (int i = 0; i < n; ++i) {
    index.add(keys[i], vectors + i * d);
}

// âœ… å¿«ï¼šæ‰¹é‡æ·»åŠ 
index.add(keys, vectors, n);
```

**3. æœªå¯ç”¨å¤šçº¿ç¨‹**
```cpp
// å¯ç”¨ OpenMP
config.multi = true;

// ç¼–è¯‘æ—¶å¯ç”¨
g++ -fopenmp ...
```

**4. ç³»ç»Ÿèµ„æºä¸è¶³**
```bash
# æ£€æŸ¥ CPU
top -p $(pidof your_program)

# æ£€æŸ¥å†…å­˜
free -h

# æ£€æŸ¥ç£ç›˜ I/O
iostat -x 1
```

---

### Q6: å¦‚ä½•æé«˜å¬å›ç‡ï¼Ÿ

**A:**

**1. å¢åŠ  expansion**
```cpp
config.expansion = 128;  // ä» 64 å¢åŠ åˆ° 128
```

**2. å¢åŠ  connectivity**
```cpp
config.connectivity = 32;  // ä» 16 å¢åŠ åˆ° 32
```

**3. ä½¿ç”¨æ›´ç²¾ç¡®çš„é‡åŒ–**
```cpp
// ä» f16 æ”¹ä¸º f32
scalar_kind_t scalar = scalar_kind_t::f32_k;
```

**4. æŸ¥è¯¢æ›´å¤šåˆ†ç‰‡**ï¼ˆåˆ†å¸ƒå¼ï¼‰
```cpp
// æŸ¥è¯¢æ‰€æœ‰åˆ†ç‰‡è€Œä¸æ˜¯éƒ¨åˆ†
auto results = cluster.search(query, k, n_shards);
```

**å¬å›ç‡ vs æ€§èƒ½æƒè¡¡**ï¼š
| expansion | å¬å›ç‡ | å»¶è¿Ÿ |
|-----------|--------|------|
| 32 | 85% | 0.5x |
| 64 | 95% | 1.0x |
| 128 | 98% | 1.5x |
| 256 | 99% | 2.0x |

---

### Q7: å¦‚ä½•å¤„ç†é«˜ç»´å‘é‡ï¼Ÿ

**A:**

**1. é™ç»´**
```cpp
// PCA é™ç»´
auto reduced = pca.transform(original_vectors, 768, 256);
```

**2. é‡åŒ–**
```cpp
// ä½¿ç”¨ f16 è€Œé f32
index.init(dimensions, metric_kind_t::cos_k, scalar_kind_t::f16_k);
```

**3. äº§å“é‡åŒ–ï¼ˆPQï¼‰**
```cpp
// å°†å‘é‡åˆ†æˆå¤šä¸ªå­å‘é‡ï¼Œåˆ†åˆ«é‡åŒ–
class ProductQuantizer {
    std::size_t n_subvectors = 8;  // 768 / 8 = 96 ç»´/å­å‘é‡
    // ...
};
```

---

## åˆ†å¸ƒå¼éƒ¨ç½²

### Q8: å¦‚ä½•é€‰æ‹©åˆ†ç‰‡æ•°é‡ï¼Ÿ

**A:**

**ç»éªŒå…¬å¼**ï¼š
```
åˆ†ç‰‡æ•° = min(æ•°æ®é‡ / å•åˆ†ç‰‡å®¹é‡, CPUæ ¸å¿ƒæ•°)

ç¤ºä¾‹ï¼š
- 1000ä¸‡å‘é‡ï¼Œå•åˆ†ç‰‡1000ä¸‡ â†’ 1 åˆ†ç‰‡
- 1äº¿å‘é‡ï¼Œå•åˆ†ç‰‡1000ä¸‡ â†’ 10 åˆ†ç‰‡
- 1äº¿å‘é‡ï¼Œ16æ ¸CPU â†’ 10 åˆ†ç‰‡ï¼ˆä¸æ˜¯16ï¼‰
```

**è€ƒè™‘å› ç´ **ï¼š
1. æ¯ä¸ªåˆ†ç‰‡ < 2000ä¸‡å‘é‡
2. åˆ†ç‰‡æ•° â‰¤ CPUæ ¸å¿ƒæ•°
3. é¢„ç•™æ‰©å±•ç©ºé—´

---

### Q9: åˆ†å¸ƒå¼ç¯å¢ƒä¸‹å¦‚ä½•ä¿è¯ä¸€è‡´æ€§ï¼Ÿ

**A:**

**1. ä½¿ç”¨ Raft å…±è¯†**
```cpp
RaftNode raft;
raft.add_vector(key, vector);  // è‡ªåŠ¨å¤åˆ¶åˆ°å¤šæ•°èŠ‚ç‚¹
```

**2. Quorum æœºåˆ¶**
```cpp
// å†™éœ€è¦ W ä¸ªç¡®è®¤ï¼Œè¯»éœ€è¦ R ä¸ªå“åº”
// W + R > N (èŠ‚ç‚¹æ€»æ•°)
class QuorumReplication {
    std::size_t write_quorum = 2;
    std::size_t read_quorum = 2;
};
```

**3. å‘é‡æ—¶é’Ÿ**
```cpp
VectorClock vc;
vc.receive(other_vc);  // åˆå¹¶æ—¶é’Ÿ
```

---

### Q10: å¦‚ä½•å¤„ç†èŠ‚ç‚¹æ•…éšœï¼Ÿ

**A:**

**1. å¿ƒè·³æ£€æµ‹**
```cpp
FailureDetector detector;
detector.add_node("shard1:5000");
detector.set_failure_callback([](auto& node) {
    handle_failure(node);
});
detector.start();
```

**2. è‡ªåŠ¨æ•…éšœè½¬ç§»**
```cpp
void handle_failure(std::string const& failed_node) {
    // 1. æ ‡è®°èŠ‚ç‚¹ä¸ºä¸å¯ç”¨
    mark_unavailable(failed_node);

    // 2. æå‡å‰¯æœ¬
    promote_replica(failed_node);

    // 3. é‡å»ºå‰¯æœ¬
    rebuild_replica(failed_node);
}
```

**3. æ£€æŸ¥ç‚¹æ¢å¤**
```cpp
CheckpointManager checkpoint_mgr;
checkpoint_mgr.restore_latest();  // æ¢å¤åˆ°æœ€æ–°æ£€æŸ¥ç‚¹
```

---

## é”™è¯¯æ’æŸ¥

### Q11: ç¼–è¯‘é”™è¯¯ "undefined reference to ..."

**A:**

**å¸¸è§åŸå› **ï¼š
1. æœªé“¾æ¥åº“
2. é“¾æ¥é¡ºåºé”™è¯¯
3. æœªåŒ…å«å¤´æ–‡ä»¶

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ­£ç¡®çš„ç¼–è¯‘å‘½ä»¤
g++ -std=c++17 -O3 \
    -I/path/to/usearch/include \
    your_code.cpp \
    -o your_program

# å¦‚æœä½¿ç”¨äº† OpenMP
g++ -std=c++17 -O3 -fopenmp \
    -I/path/to/usearch/include \
    your_code.cpp \
    -o your_program
```

---

### Q12: è¿è¡Œæ—¶é”™è¯¯ "Segmentation fault"

**A:**

**è°ƒè¯•æ­¥éª¤**ï¼š

**1. ä½¿ç”¨ GDB**
```bash
gdb ./your_program
(gdb) run
(gdb) bt  # æŸ¥çœ‹å †æ ˆ
```

**2. ä½¿ç”¨ Valgrind**
```bash
valgrind --leak-check=full ./your_program
```

**3. å¸¸è§åŸå› **
```cpp
// âŒ é”™è¯¯ï¼šæœªåˆå§‹åŒ–ç´¢å¼•
index_dense_gt<float, uint32_t> index;
index.search(query, 10);  // å´©æºƒï¼

// âœ… æ­£ç¡®ï¼šå…ˆåˆå§‹åŒ–
index.init(128, metric_kind_t::cos_k);
index.search(query, 10);

// âŒ é”™è¯¯ï¼šç»´åº¦ä¸åŒ¹é…
index.init(128);
// ... ä½†æŸ¥è¯¢å‘é‡æ˜¯ 256 ç»´

// âœ… æ­£ç¡®ï¼šç¡®ä¿ç»´åº¦ä¸€è‡´
float query[128];
index.search(query, 10);
```

---

### Q13: å†…å­˜æ³„æ¼æ€ä¹ˆåŠï¼Ÿ

**A:**

**1. æ£€æµ‹æ³„æ¼**
```bash
valgrind --leak-check=full \
         --show-leak-kinds=all \
         --track-origins=yes \
         ./your_program
```

**2. å¸¸è§åŸå› **
```cpp
// âŒ å¾ªç¯å¼•ç”¨
std::shared_ptr<Node> a = std::make_shared<Node>();
std::shared_ptr<Node> b = std::make_shared<Node>();
a->next = b;
b->prev = a;  // å¾ªç¯å¼•ç”¨ï¼

// âœ… ä½¿ç”¨ weak_ptr æ‰“ç ´å¾ªç¯
std::shared_ptr<Node> a = std::make_shared<Node>();
std::shared_ptr<Node> b = std::make_shared<Node>();
a->next = b;
b->prev = std::weak_ptr<Node>(a);  // weak_ptr
```

**3. USearch ç‰¹å®š**
```cpp
// USearch å†…éƒ¨ç®¡ç†å†…å­˜ï¼Œé€šå¸¸ä¸ä¼šæ³„æ¼
// å¦‚æœæ€€ç–‘æ³„æ¼ï¼Œæ£€æŸ¥ï¼š
// 1. æ˜¯å¦æ­£ç¡®åˆ é™¤ç´¢å¼•
// 2. æ˜¯å¦æœ‰çº¿ç¨‹æœªé€€å‡º
// 3. æ˜¯å¦æœ‰å¾ªç¯å¼•ç”¨
```

---

## æœ€ä½³å®è·µ

### Q14: å¦‚ä½•è®¾è®¡ä¸€ä¸ªå¥½çš„å‘é‡ç´¢å¼•ç³»ç»Ÿï¼Ÿ

**A:**

**1. å®¹é‡è§„åˆ’**
```python
# ä¼°ç®—èµ„æº
n_vectors = 10_000_000
dimensions = 768
years = 3

# è€ƒè™‘å¢é•¿
total_vectors = n_vectors * (1 + 0.5 * years)  # æ¯å¹´å¢é•¿50%

# ä¼°ç®—å†…å­˜
memory_gb = estimate_memory(total_vectors, dimensions, 'f16')

# ç¡¬ä»¶é…ç½®
print(f"éœ€è¦å†…å­˜: {memory_gb:.1f} GB")
print(f"æ¨èé…ç½®: {memory_gb * 2:.1f} GB (ç•™æœ‰ä½™é‡)")
```

**2. åˆ†å±‚æ¶æ„**
```cpp
// çƒ­æ•°æ®ï¼šå†…å­˜ï¼Œæœ€å¿«
index_dense_gt<float, uint32_t> hot_index;

// æ¸©æ•°æ®ï¼šSSDï¼Œä¸­ç­‰
index_dense_gt<float, uint32_t> warm_index;

// å†·æ•°æ®ï¼šå½’æ¡£
void archive_old_data();
```

**3. ç›‘æ§å’Œå‘Šè­¦**
```python
# å…³é”®æŒ‡æ ‡
metrics = {
    'qps': queries_per_second,
    'latency_p99': percentile_99(latencies),
    'recall': calculate_recall(test_set),
    'memory_usage': get_memory_usage(),
}

# å‘Šè­¦
if metrics['latency_p99'] > threshold:
    send_alert("High latency!")
```

---

### Q15: å¦‚ä½•å¤„ç†å®æ—¶æ•°æ®æ›´æ–°ï¼Ÿ

**A:**

**1. å¢é‡æ›´æ–°**
```cpp
class IncrementalUpdater {
    std::queue<update_t> updates_;

    void add_update(update_t const& update) {
        updates_.push(update);

        if (updates_.size() >= BATCH_SIZE) {
            flush();
        }
    }

    void flush() {
        // æ‰¹é‡åº”ç”¨æ›´æ–°
        while (!updates_.empty()) {
            auto u = updates_.front();
            updates_.pop();
            apply_update(u);
        }
    }
};
```

**2. å®šæœŸé‡å»º**
```cpp
// æ¯å¤©å‡Œæ™¨é‡å»ºç´¢å¼•
void periodic_rebuild() {
    while (true) {
        wait_until_next_day();

        auto new_index = build_index_from_source();
        atomic_store(&active_index, new_index);
    }
}
```

**3. ç‰ˆæœ¬ç®¡ç†**
```cpp
class VersionedIndex {
    std::atomic<index_dense_gt*> current_;

    void update_index() {
        auto new_index = new index_dense_gt();
        // ... æ„å»ºæ–°ç´¢å¼• ...

        // åŸå­åˆ‡æ¢
        auto old = current_.exchange(new_index);

        // å»¶è¿Ÿåˆ é™¤æ—§ç´¢å¼•
        schedule_delete(old);
    }
};
```

---

## é›†æˆé—®é¢˜

### Q16: å¦‚ä½•ä¸æ·±åº¦å­¦ä¹ æ¡†æ¶é›†æˆï¼Ÿ

**A:**

**PyTorch é›†æˆ**ï¼š
```python
import torch
from usearch.index import Index

# æå–ç‰¹å¾
model = ResNet50(pretrained=True)
model.eval()

with torch.no_grad():
    features = model(image_tensor)  # [1, 2048]
    embedding = features.cpu().numpy().flatten()

# æ·»åŠ åˆ°ç´¢å¼•
index = Index(ndim=2048, metric='cos')
index.add([image_id], [embedding])

# æœç´¢
results = index.search(embedding, k=10)
```

**TensorFlow é›†æˆ**ï¼š
```python
import tensorflow as tf
from usearch.index import Index

# ä½¿ç”¨ TF-Hub
module = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2')
features = module(image_tensor)

# æ·»åŠ åˆ°ç´¢å¼•
index.add([image_id], [features.numpy()])
```

---

### Q17: å¦‚ä½•ä¸æ•°æ®åº“é›†æˆï¼Ÿ

**A:**

**PostgreSQL + USearch**ï¼š
```python
import psycopg2
from usearch.index import Index

# 1. ä»æ•°æ®åº“è¯»å–æ•°æ®
conn = psycopg2.connect("dbname=test user=postgres")
cur = conn.cursor()

cur.execute("SELECT id, embedding FROM products")
rows = cur.fetchall()

# 2. æ„å»ºå‘é‡ç´¢å¼•
index = Index(ndim=768, metric='cos')
ids = [row[0] for row in rows]
embeddings = [row[1] for row in rows]
index.add(ids, embeddings)

# 3. æœç´¢å¹¶è·å–å®Œæ•´ä¿¡æ¯
results = index.search(query_embedding, k=10)

for r in results:
    cur.execute("SELECT * FROM products WHERE id = %s", (r.key,))
    product = cur.fetchone()
    print(f"Product: {product[1]}, Score: {r.distance}")
```

**MongoDB + USearch**ï¼š
```python
from pymongo import MongoClient
from usearch.index import Index

client = MongoClient('mongodb://localhost:27017/')
db = client['ecommerce']
collection = db['products']

# å‘é‡æœç´¢ + å…ƒæ•°æ®è¿‡æ»¤
results = index.search(query, k=100)

# åº”ç”¨ MongoDB è¿‡æ»¤
filtered = []
for r in results:
    doc = collection.find_one({'_id': r.key})
    if doc and doc['price'] < 100:  # ä»·æ ¼è¿‡æ»¤
        filtered.append(doc)

print(sorted(filtered, key=lambda x: x['rating'])[:10])
```

---

### Q18: Web API å¦‚ä½•å®ç°ï¼Ÿ

**A:**

**Flask API**ï¼š
```python
from flask import Flask, request, jsonify
from usearch.index import Index

app = Flask(__name__)
index = Index(ndim=768, metric='cos')

@app.route('/add', methods=['POST'])
def add_vectors():
    data = request.json
    index.add(data['ids'], data['vectors'])
    return jsonify({'status': 'ok'})

@app.route('/search', methods=['POST'])
def search():
    data = request.json
    results = index.search(data['query'], k=data.get('k', 10))
    return jsonify({
        'results': [
            {'id': int(r.key), 'score': float(r.distance)}
            for r in results
        ]
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

**FastAPIï¼ˆå¼‚æ­¥ï¼‰**ï¼š
```python
from fastapi import FastAPI
from usearch.index import Index
import numpy as np

app = FastAPI()
index = Index(ndim=768, metric='cos')

@app.post("/search")
async def search(query: List[float], k: int = 10):
    query_array = np.array(query, dtype=np.float32)
    results = index.search(query_array, k)
    return {
        "results": [
            {"id": int(r.key), "score": float(r.distance)}
            for r in results
        ]
    }
```

---

## å…¶ä»–å¸¸è§é—®é¢˜

### Q19: USearch æ”¯æŒå“ªäº›å¹³å°ï¼Ÿ

**A:**

| å¹³å° | æ”¯æŒçŠ¶æ€ | å¤‡æ³¨ |
|------|---------|------|
| Linux x86_64 | âœ… å®Œå…¨æ”¯æŒ | æ¨è |
| Linux ARM64 | âœ… å®Œå…¨æ”¯æŒ | æ ‘è“æ´¾ç­‰ |
| macOS x86_64 | âœ… å®Œå…¨æ”¯æŒ | |
| macOS ARM64 | âœ… å®Œå…¨æ”¯æŒ | M1/M2 |
| Windows x86_64 | âœ… å®Œå…¨æ”¯æŒ | éœ€è¦ MSVC |
| Windows ARM64 | âš ï¸ å®éªŒæ€§ | |

**ç¼–è¯‘é€‰é¡¹**ï¼š
```bash
# Linux/macOS
g++ -std=c++17 -O3 -march=native ...

# Windows (MSVC)
cl /std:c++17 /O2 /arch:AVX2 ...
```

---

### Q20: å¦‚ä½•è´¡çŒ®ä»£ç ï¼Ÿ

**A:**

1. Fork ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
   ```bash
   git checkout -b feature/my-feature
   ```
3. æäº¤æ›´æ”¹
   ```bash
   git commit -am 'Add some feature'
   ```
4. æ¨é€åˆ°åˆ†æ”¯
   ```bash
   git push origin feature/my-feature
   ```
5. åˆ›å»º Pull Request

**ä»£ç è§„èŒƒ**ï¼š
- éµå¾ªç°æœ‰ä»£ç é£æ ¼
- æ·»åŠ æµ‹è¯•
- æ›´æ–°æ–‡æ¡£
- é€šè¿‡ CI æ£€æŸ¥

---

### Q21: æ€§èƒ½åŸºå‡†åœ¨å“ªé‡Œï¼Ÿ

**A:**

**è¿è¡ŒåŸºå‡†æµ‹è¯•**ï¼š
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/unum-cloud/usearch.git
cd usearch

# ç¼–è¯‘åŸºå‡†æµ‹è¯•
mkdir build && cd build
cmake .. -DUSEARCH_BUILD_BENCH_CPP=ON
make -j$(nproc)

# è¿è¡Œ
./bench_cpp
```

**é¢„æœŸæ€§èƒ½**ï¼ˆ1000ä¸‡ 768ç»´å‘é‡ï¼‰ï¼š
| æ“ä½œ | æ—¶é—´ | QPS |
|------|------|-----|
| æ„å»ºç´¢å¼• | ~5 åˆ†é’Ÿ | - |
| å•æ¬¡æœç´¢ | ~1 ms | ~1000 |
| æ‰¹é‡æœç´¢(100) | ~10 ms | ~10000 |

---

## è·å–å¸®åŠ©

å¦‚æœä»¥ä¸ŠFAQæ²¡æœ‰è§£å†³ä½ çš„é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ–‡æ¡£**ï¼š`README.md`ã€`INDEX.md`
2. **æœç´¢Issues**ï¼šGitHub Issues
3. **æé—®**ï¼š
   - Stack Overflowï¼ˆæ ‡ç­¾ `usearch`ï¼‰
   - GitHub Discussions
4. **è”ç³»**ï¼šGitHub Issues

---

**ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-01-24
**ç»´æŠ¤è€…**: USearch ç¤¾åŒº
